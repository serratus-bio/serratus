{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run: pmito5 - Mitovirus/Narnavirus pilot\n",
    "\n",
    "```\n",
    "Lead     : ababaian\n",
    "Issue    : \n",
    "Version  : v0.3.5-dev : diamond-dev branch\n",
    "start    : 2020 10 25\n",
    "complete : 2020 10 26\n",
    "files    : ~/serratus/notebook/201012_ab/\n",
    "s3_files : s3://serratus-public/notebook/201012_ab/\n",
    "output   : s3://serratus-public/out/201025_pmito5/\n",
    "```\n",
    "\n",
    "### Intro/Objectives\n",
    "\n",
    "- Run protref5b against some test human RNAseq and ~1,000 random viromes for pilot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire up EC2 Instance\n",
    "sudo yum install -y docker\n",
    "sudo yum install -y git\n",
    "sudo service docker start\n",
    "\n",
    "# Download latest serratus repo\n",
    "git clone -b diamond-dev https://github.com/ababaian/serratus.git; cd serratus/containers\n",
    "\n",
    "# If you want to upload containers to your repository, include this.\n",
    "export DOCKERHUB_USER='serratusbio' # optional\n",
    "sudo docker login # optional\n",
    "\n",
    "# Build all containers and upload them docker hub repo (if available)\n",
    "./build_containers.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virome + Metatranscriptome\n",
    "\n",
    "Query: `\"VIRAL METAGENOME\" OR \"VIROME\" OR \"VIROMIC\" OR \"VIRAL RNA\" OR \"METATRANSCRIPTOMIC\" NOT \"METAGENOMIC\" NOT amplicon[All Fields] AND \"platform illumina\"[Properties] AND cluster_public[prop]`\n",
    "\n",
    "Date: `2000904`\n",
    "Return: `60327`\n",
    "\n",
    "Sub-sample to 1000 datasets\n",
    "\n",
    "## Human test data\n",
    "\n",
    "Query: `SRP163252`\n",
    "\n",
    "Date: `201025`\n",
    "Return: `165`\n",
    "\n",
    "\n",
    "Saved to \"$WORK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 25 19:49:27 PDT 2020\n",
      "fde8446fbf106afff5ec1c82941f154fc39c97f7\n"
     ]
    }
   ],
   "source": [
    "# Serratus commit version\n",
    "SERRATUS=\"/home/artem/serratus\"\n",
    "cd $SERRATUS\n",
    "\n",
    "# Create local run directory\n",
    "WORK=\"$SERRATUS/notebook/201012_ab\"\n",
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# S3 notebook path\n",
    "S3_WORK='s3://serratus-public/notebook/201012_ab/'\n",
    "\n",
    "# date and version\n",
    "date\n",
    "git rev-parse HEAD # commit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf: write error: Broken pipe\n",
      "shuf: write error\n",
      "     167 hutest_SraRunInfo.csv\n",
      "    1001 viro1k_SraRunInfo.csv\n",
      "   61466 viro_SraRunInfo.csv\n",
      "   62634 total\n",
      "26d72d550701deeeb578ca8399da8629  hutest_SraRunInfo.csv\n",
      "c16a1b2da03eaf1088933a1de329ce2f  viro1k_SraRunInfo.csv\n",
      "2ddb64e9f5706fd64354a45f296592b4  viro_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 1000 viro samples\n",
    "head -n1 viro_SraRunInfo.csv > sra.header\n",
    "\n",
    "# Inverse select viro and vert\n",
    "shuf viro_SraRunInfo.csv | head -n 1000 > viro1k.tmp\n",
    "\n",
    "cat sra.header viro1k.tmp \\\n",
    "  > viro1k_SraRunInfo.csv\n",
    "\n",
    "rm viro1k.tmp\n",
    "wc -l *.csv\n",
    "md5sum *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 sync ./ $S3_WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terraform Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/terraform/main/main.tf b/terraform/main/main.tf\n",
      "index de2d00d..33bf4e8 100644\n",
      "--- a/terraform/main/main.tf\n",
      "+++ b/terraform/main/main.tf\n",
      "@@ -12,14 +12,14 @@ variable \"aws_region\" {\n",
      " }\n",
      " \n",
      " variable \"dl_size\" {\n",
      "-  type    = number\n",
      "-  default = 0\n",
      "+  type        = number\n",
      "+  default     = 0\n",
      "   description = \"Default number of downloader nodes (ASG)\"\n",
      " }\n",
      " \n",
      " variable \"align_size\" {\n",
      "-  type    = number\n",
      "-  default = 0\n",
      "+  type        = number\n",
      "+  default     = 0\n",
      "   description = \"Default number of aligner nodes (ASG)\"\n",
      " }\n",
      " \n",
      "@@ -38,14 +38,22 @@ variable \"dockerhub_account\" {\n",
      " }\n",
      " \n",
      " variable \"scheduler_port\" {\n",
      "-  type  = number\n",
      "+  type    = number\n",
      "   default = 8000\n",
      " }\n",
      " \n",
      "+variable \"output_bucket\" {\n",
      "+  type = string\n",
      "+}\n",
      "+\n",
      "+//variable \"metrics_ip\" {\n",
      "+//  type = string\n",
      "+//}\n",
      "+\n",
      " // PROVIDER/AWS ##############################\n",
      " provider \"aws\" {\n",
      "-  version     = \"~> 2.49\"\n",
      "-  region      = var.aws_region\n",
      "+  version = \"~> 2.49\"\n",
      "+  region  = var.aws_region\n",
      " }\n",
      " \n",
      " provider \"local\" {\n",
      "@@ -81,67 +89,72 @@ resource \"aws_security_group\" \"internal\" {\n",
      " \n",
      " // Working S3 storage for Serratus\n",
      " module \"work_bucket\" {\n",
      "-  source   = \"../bucket\"\n",
      "+  source = \"../bucket\"\n",
      " \n",
      "   prefixes = [\"fq-blocks\", \"bam-blocks\", \"out\"]\n",
      " }\n",
      " \n",
      " // Cluster scheduler and task manager\n",
      " module \"scheduler\" {\n",
      "-  source             = \"../scheduler\"\n",
      "-  \n",
      "+  source = \"../scheduler\"\n",
      "+\n",
      "   security_group_ids = [aws_security_group.internal.id]\n",
      "   key_name           = var.key_name\n",
      "-  instance_type      = \"c5.large\"\n",
      "+  instance_type      = \"r5.4xlarge\"\n",
      "   dockerhub_account  = var.dockerhub_account\n",
      "   scheduler_port     = var.scheduler_port\n",
      "+\n",
      "+  //# https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server\n",
      "+  //pg_shared_buffers  = \"2GB\" # 1/4 of RAM\n",
      "+  //pg_effective_cache = \"6GB\" # 3/4 of RAM\n",
      " }\n",
      " \n",
      " // Cluster monitor\n",
      " module \"monitoring\" {\n",
      "-  source             = \"../monitoring\"\n",
      "+  source = \"../monitoring\"\n",
      " \n",
      "   security_group_ids = [aws_security_group.internal.id]\n",
      "   key_name           = var.key_name\n",
      "   scheduler_ip       = module.scheduler.private_ip\n",
      "+  //metrics_ip         = var.metrics_ip\n",
      "   dockerhub_account  = var.dockerhub_account\n",
      "-  instance_type      = \"r5.large\"\n",
      "+  instance_type      = \"r5.4xlarge\"\n",
      " }\n",
      " \n",
      " // Serratus-dl\n",
      " module \"download\" {\n",
      "-  source             = \"../worker\"\n",
      "+  source = \"../worker\"\n",
      " \n",
      "-  desired_size       = 0\n",
      "-  max_size           = 200\n",
      "+  desired_size = 0\n",
      "+  max_size     = 5000\n",
      " \n",
      "   dev_cidrs          = var.dev_cidrs\n",
      "   security_group_ids = [aws_security_group.internal.id]\n",
      " \n",
      "-  instance_type      = \"r5.large\" // Mitigate the memory leak in fastq-dump\n",
      "-  volume_size        = 250 // Mitigate the storage leak in fastq-dump\n",
      "-  spot_price         = 0.10\n",
      "+  instance_type = \"r5.xlarge\" // Mitigate the memory leak in fastq-dump\n",
      "+  volume_size   = 100         // Mitigate the storage leak in fastq-dump\n",
      "+  spot_price    = 0.10\n",
      " \n",
      "-  s3_bucket          = module.work_bucket.name\n",
      "-  s3_prefix          = \"fq-blocks\"\n",
      "+  s3_bucket = module.work_bucket.name\n",
      "+  s3_prefix = \"fq-blocks\"\n",
      " \n",
      "-  image_name         = \"serratus-dl\"\n",
      "-  dockerhub_account  = var.dockerhub_account\n",
      "-  key_name           = var.key_name\n",
      "-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\n",
      "-  options            = \"-k ${module.work_bucket.name}\"\n",
      "+  image_name        = \"serratus-dl\"\n",
      "+  dockerhub_account = var.dockerhub_account\n",
      "+  key_name          = var.key_name\n",
      "+  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\n",
      "+  options           = \"-k ${module.work_bucket.name}\"\n",
      " }\n",
      " \n",
      " // Serratus-align\n",
      " module \"align\" {\n",
      "-  source             = \"../worker\"\n",
      "+  source = \"../worker\"\n",
      " \n",
      "   desired_size       = 0\n",
      "-  max_size           = 500\n",
      "+  max_size           = 10000\n",
      "   dev_cidrs          = var.dev_cidrs\n",
      "   security_group_ids = [aws_security_group.internal.id]\n",
      "-  instance_type      = \"c5.large\" # c5.large\n",
      "-  volume_size        = 10\n",
      "+  instance_type      = \"c5.xlarge\" # c5.large\n",
      "+  volume_size        = 12\n",
      "   spot_price         = 0.10\n",
      "   s3_bucket          = module.work_bucket.name\n",
      "   s3_delete_prefix   = \"fq-blocks\"\n",
      "@@ -150,51 +163,46 @@ module \"align\" {\n",
      "   image_name         = \"serratus-align\"\n",
      "   key_name           = var.key_name\n",
      "   scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\n",
      "-  options            = \"-k ${module.work_bucket.name} -a bowtie2\"\n",
      "+  options            = \"-k ${module.work_bucket.name} -a diamond\"\n",
      " }\n",
      " \n",
      " //Serratus-merge\n",
      " module \"merge\" {\n",
      "-  source             = \"../worker\"\n",
      "+  source = \"../worker\"\n",
      " \n",
      "   desired_size       = 0\n",
      "-  max_size           = 50\n",
      "+  max_size           = 500\n",
      "   dev_cidrs          = var.dev_cidrs\n",
      "   security_group_ids = [aws_security_group.internal.id]\n",
      "   instance_type      = \"c5.large\"\n",
      "   volume_size        = 150 // prevent disk overflow via samtools cat\n",
      "   spot_price         = 0.05\n",
      "   s3_bucket          = module.work_bucket.name\n",
      "-  // TODO: Add delete permissions for *-blocks\n",
      "-  // to merge as redundant delete of completed data\n",
      "-  s3_delete_prefix   = \"bam-blocks\"\n",
      "-  s3_prefix          = \"out\"\n",
      "-  dockerhub_account  = var.dockerhub_account\n",
      "-  image_name         = \"serratus-merge\"\n",
      "-  key_name           = var.key_name\n",
      "-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\n",
      "-  // TODO: the credentials are not properly set-up to\n",
      "-  //       upload to serratus-public, requires a *Object policy\n",
      "-  //       on the bucket.\n",
      "-  options            = \"-k ${module.work_bucket.name} -b ${var.output_bucket}\"\n",
      "+  s3_delete_prefix  = \"bam-blocks\"\n",
      "+  s3_prefix         = \"out\"\n",
      "+  dockerhub_account = var.dockerhub_account\n",
      "+  image_name        = \"serratus-merge\"\n",
      "+  key_name          = var.key_name\n",
      "+  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\n",
      "+  options = \"-k ${module.work_bucket.name} -b s3://serratus-public/out/201025_pmito5\"\n",
      " }\n",
      " \n",
      " // RESOURCES ##############################\n",
      " // Controller scripts created locally\n",
      " \n",
      " resource \"local_file\" \"hosts\" {\n",
      "-  filename = \"${path.module}/serratus-hosts\"\n",
      "+  filename        = \"${path.module}/serratus-hosts\"\n",
      "   file_permission = 0666\n",
      "-  content = <<-EOF\n",
      "+  content         = <<-EOF\n",
      "     aws_monitor ${module.monitoring.public_dns}\n",
      "     aws_scheduler ${module.scheduler.public_dns}\n",
      "   EOF\n",
      " }\n",
      " \n",
      " resource \"local_file\" \"create_tunnel\" {\n",
      "-  filename = \"${path.module}/create_tunnels.sh\"\n",
      "+  filename        = \"${path.module}/create_tunnels.sh\"\n",
      "   file_permission = 0777\n",
      "-  content = <<-EOF\n",
      "+  content         = <<-EOF\n",
      "     #!/bin/bash\n",
      "     set -eu\n",
      "     ssh -Nf -L 3000:localhost:3000 -L 9090:localhost:9090 ec2-user@${module.monitoring.public_dns}\n",
      "@@ -208,9 +216,9 @@ resource \"local_file\" \"create_tunnel\" {\n",
      " }\n",
      " \n",
      " resource \"local_file\" \"upload_sra\" {\n",
      "-  filename = \"${path.module}/uploadSRA.sh\"\n",
      "+  filename        = \"${path.module}/uploadSRA.sh\"\n",
      "   file_permission = 0777\n",
      "-  content = <<-EOF\n",
      "+  content         = <<-EOF\n",
      "     #!/bin/bash\n",
      "     # =====================================\n",
      "     # Serratus - uploadSRA.sh\n",
      "@@ -289,7 +297,6 @@ resource \"local_file\" \"upload_sra\" {\n",
      "   EOF\n",
      " }\n",
      " \n",
      "-\n",
      " // OUTPUT ##############################\n",
      " output \"help\" {\n",
      "   value = <<-EOF\n",
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "\n",
      "The following providers do not have any version constraints in configuration,\n",
      "so the latest version was installed.\n",
      "\n",
      "To prevent automatic upgrades to new major versions that may contain breaking\n",
      "changes, it is recommended to add version = \"...\" constraints to the\n",
      "corresponding provider blocks in configuration, with the constraint strings\n",
      "suggested below.\n",
      "\n",
      "* provider.random: version = \"~> 2.2\"\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.download.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creation complete after 0s [id=none]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creation complete after 0s [id=db5deb3269742410535713cc6c7c3d53cbb21cfe]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 2s [id=SerratusEcsInstanceRole-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creation complete after 2s [id=serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creation complete after 2s [id=serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creation complete after 2s [id=serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creation complete after 2s [id=serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creation complete after 2s [id=serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-align:CloudWatchLogsCreate-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-align-20201026031443260700000002]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor-20201026031444077600000003]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creation complete after 1s [id=SerratusIamRole-scheduler:DescribeInstances-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creation complete after 1s [id=scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 2s [id=instance-profile-serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-align:DescribeEC2Instances-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 1s [id=instance-profile-serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-align:AdjustAutoScaling-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler-20201026031445203900000004]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-monitor:CloudwatchGetMetrics]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-align:TerminateEC2Instances-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creation complete after 1s [id=SerratusIamRole-monitor-20201026031445731600000005]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-dl:CloudWatchLogsCreate-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-dl-20201026031446137100000006]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-merge-20201026031446223300000007]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creation complete after 5s [id=sg-05d3672e5be6286b6]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-merge:CloudWatchLogsCreate-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-dl:DescribeEC2Instances-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-dl:AdjustAutoScaling-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-dl:TerminateEC2Instances-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 2s [id=profile-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-merge:TerminateEC2Instances-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-merge:AdjustAutoScaling-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-merge:DescribeEC2Instances-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creation complete after 8s [id=tf-serratus-work-20201026031442392700000001]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20201026031442392700000001:prefix-bam-blocks]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20201026031442392700000001:prefix-fq-blocks]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creation complete after 1s [id=tf-serratus-work-20201026031442392700000001:prefix-out]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creation complete after 1s [id=tf-serratus-work-20201026031442392700000001:full]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3DeleteData-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3WriteData-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3DeleteData-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creation complete after 2s [id=SerratusIamRole-serratus-dl:S3WriteData-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3WriteData-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 12s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 11s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-0e4b1369beea2c9cc]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creation complete after 17s [id=i-0fee2c4ddbfc58812]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creation complete after 1s [id=monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creation complete after 4s [id=eipalloc-0209d38c8853024b7]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creation complete after 3s [id=eipalloc-04c947308622dac4d]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creation complete after 0s [id=15cd74eb70319fc862a5f455f7448847d70a94a0]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creation complete after 0s [id=9807b6b9a021d64f6cdf26d8a101a340452bc315]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-merge-2020102603151495760000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-dl-2020102603151494160000000b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-align-2020102603151494160000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-dl-2020102603151494160000000b]\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-align-2020102603151494160000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-merge-2020102603151495760000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-align-2020102603151494160000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-dl-2020102603151494160000000b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creation complete after 2s [id=serratus-merge-2020102603151495760000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 71 added, 0 changed, 0 destroyed.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "align_asg_name = serratus-align-2020102603151494160000000a\n",
      "dl_asg_name = serratus-dl-2020102603151494160000000b\n",
      "help = Run ./create_tunnels.sh to create SSH tunnels for all services.\n",
      "\n",
      "merge_asg_name = serratus-merge-2020102603151495760000000c\n",
      "monitor_dns = ec2-54-198-243-217.compute-1.amazonaws.com\n",
      "scheduler_dns = ec2-107-22-55-245.compute-1.amazonaws.com\n",
      "scheduler_pg_password = JJPRvwWBbJM9TLMM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For rapid batching; copy out serratus folder\n",
    "# PROTEIN / DNA MUST BE SET IN CONFIG FILE\n",
    "# LINE 153\n",
    "#   options            = \"-k ${module.work_bucket.name} -a bowtie2\"\n",
    "#   options            = \"-k ${module.work_bucket.name} -a diamond\"\n",
    "\n",
    "TF=$SERRATUS/terraform/main\n",
    "cd $TF\n",
    "git diff main.tf\n",
    "terraform init\n",
    "\n",
    "# Launch Terraform Cluster\n",
    "# Initialize the serratus cluster with minimal nodes\n",
    "terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serratus Config backup \n",
    "```\n",
    "{\n",
    "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\n",
    "  \"ALIGN_MAX_INCREASE\": 25,\n",
    "  \"ALIGN_SCALING_CONSTANT\": 0.0215,\n",
    "  \"ALIGN_SCALING_ENABLE\": true,\n",
    "  \"ALIGN_SCALING_MAX\": 20,\n",
    "  \"CLEAR_INTERVAL\": 999999,\n",
    "  \"DL_ARGS\": \"\",\n",
    "  \"DL_MAX_INCREASE\": 10,\n",
    "  \"DL_SCALING_CONSTANT\": 0.1,\n",
    "  \"DL_SCALING_ENABLE\": true,\n",
    "  \"DL_SCALING_MAX\": 10,\n",
    "  \"GENOME\": \"protref5b\",\n",
    "  \"MERGE_ARGS\": \"protein\",\n",
    "  \"MERGE_MAX_INCREASE\": 25,\n",
    "  \"MERGE_SCALING_CONSTANT\": 0.1,\n",
    "  \"MERGE_SCALING_ENABLE\": true,\n",
    "  \"MERGE_SCALING_MAX\": 20,\n",
    "  \"SCALING_INTERVAL\": 120,\n",
    "  \"VIRTUAL_SCALING_INTERVAL\": 35\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'ec2-54-198-243-217.compute-1.amazonaws.com,54.198.243.217' (ECDSA) to the list of known hosts.\n",
      "Warning: Permanently added 'ec2-107-22-55-245.compute-1.amazonaws.com,107.22.55.245' (ECDSA) to the list of known hosts.\n",
      "bind [127.0.0.1]:5432: Address already in use\n",
      "Tunnels created:\n",
      "    localhost:3000 = grafana\n",
      "    localhost:9090 = prometheus\n",
      "    localhost:5432 = postgres\n",
      "    localhost:8000 = scheduler\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "\n",
    "# Open SSH tunnels to the monitor\n",
    "./create_tunnels.sh\n",
    "\n",
    "# If you get an error on port\n",
    "# run:\n",
    "# ps aux | grep ssh\n",
    "# sudo kill <PID of SSH>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 /home/artem/serratus/notebook/201012_ab/hutest_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "BATCH='hutest_SraRunInfo.csv'\n",
    "wc -l $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \n",
      "  File: /home/artem/serratus/notebook/201012_ab/hutest_SraRunInfo.csv\n",
      "  date: Sun Oct 25 20:18:35 PDT 2020\n",
      "  wc  : 167 /home/artem/serratus/notebook/201012_ab/hutest_SraRunInfo.csv\n",
      "  md5 : 26d72d550701deeeb578ca8399da8629  /home/artem/serratus/notebook/201012_ab/hutest_SraRunInfo.csv\n",
      "\n",
      "\n",
      "--------------------------\n",
      "tmp.chunk00\n",
      "167 tmp.chunk00_sraRunInfo.csv\n",
      "a8d3ed0c9f1f568a5a6c579aafb456ca  tmp.chunk00_sraRunInfo.csv\n",
      "{\"inserted_rows\":165,\"total_rows\":165}\n",
      "\n",
      "\n",
      " uploadSRA complete.\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 /home/artem/serratus/notebook/201012_ab/viro1k_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "BATCH='viro1k_SraRunInfo.csv'\n",
    "wc -l $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \n",
      "  File: /home/artem/serratus/notebook/201012_ab/viro1k_SraRunInfo.csv\n",
      "  date: Sun Oct 25 21:06:48 PDT 2020\n",
      "  wc  : 1001 /home/artem/serratus/notebook/201012_ab/viro1k_SraRunInfo.csv\n",
      "  md5 : c16a1b2da03eaf1088933a1de329ce2f  /home/artem/serratus/notebook/201012_ab/viro1k_SraRunInfo.csv\n",
      "\n",
      "\n",
      "--------------------------\n",
      "tmp.chunk00\n",
      "1001 tmp.chunk00_sraRunInfo.csv\n",
      "06499ae61832717317e82b73b364cd86  tmp.chunk00_sraRunInfo.csv\n",
      "{\"inserted_rows\":1000,\"total_rows\":1165}\n",
      "\n",
      "\n",
      " uploadSRA complete.\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Serratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cluster Config File: \n",
      "{\n",
      "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\n",
      "  \"ALIGN_MAX_INCREASE\": 25,\n",
      "  \"ALIGN_SCALING_CONSTANT\": 0.1,\n",
      "  \"ALIGN_SCALING_ENABLE\": true,\n",
      "  \"ALIGN_SCALING_MAX\": 500,\n",
      "  \"CLEAR_INTERVAL\": 999999,\n",
      "  \"DL_ARGS\": \"\",\n",
      "  \"DL_MAX_INCREASE\": 10,\n",
      "  \"DL_SCALING_CONSTANT\": 0.1,\n",
      "  \"DL_SCALING_ENABLE\": true,\n",
      "  \"DL_SCALING_MAX\": 300,\n",
      "  \"GENOME\": \"protref5b\",\n",
      "  \"MERGE_ARGS\": \"protein\",\n",
      "  \"MERGE_MAX_INCREASE\": 25,\n",
      "  \"MERGE_SCALING_CONSTANT\": 0.1,\n",
      "  \"MERGE_SCALING_ENABLE\": true,\n",
      "  \"MERGE_SCALING_MAX\": 20,\n",
      "  \"SCALING_INTERVAL\": 120,\n",
      "  \"VIRTUAL_SCALING_INTERVAL\": 35\n",
      "}\n",
      "\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0{\"ALIGN_ARGS\":\"--very-sensitive-local\",\"ALIGN_MAX_INCREASE\":25,\"ALIGN_SCALING_CONSTANT\":0.1,\"ALIGN_SCALING_ENABLE\":true,\"ALIGN_SCALING_MAX\":500,\"CLEAR_INTERVAL\":999999,\"DL_ARGS\":\"\",\"DL_MAX_INCREASE\":10,\"DL_SCALING_CONSTANT\":0.1,\"DL_SCALING_ENABLE\":true,\"DL_SCALING_MAX\":300,\"GENOME\":\"protref5b\",\"MERGE_ARGS\":\"protein\",\"MERGE_MAX_INCREASE\":25,\"MERGE_SCALING_CONSTANT\":0.1,\"MERGE_SCALING_ENABLE\":true,\"MERGE_SCALING_MAX\":20,\"SCALING_INTERVAL\":120,\"VIRTUAL_SCALING_INTERVAL\":35}\n",
      "100  1028  100   476  100   552   1025   1189 --:--:-- --:--:-- --:--:--  2215\n"
     ]
    }
   ],
   "source": [
    "# Set Cluster Parameters =============================\n",
    "## get Config File (if it doesn't exist)\n",
    "# curl localhost:8000/config | jq > serratus-config.json\n",
    "\n",
    "cd $TF\n",
    "# Make local changes to config file\n",
    "echo \"  Cluster Config File: \"\n",
    "cat serratus-config.json\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "# Re-upload config file\n",
    "curl -T serratus-config.json localhost:8000/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop postgres if it's running \n",
    "# systemctl stop postgresql\n",
    "\n",
    "## Connect to postgres\n",
    "# psql -h localhost postgres postgres\n",
    "\n",
    "#  psql -h localhost postgres postgres -c \"DELETE FROM blocks WHERE state = 'done';\"\n",
    "\n",
    "### ACCESSION OPERATIONS\n",
    "## Reset SPLITTING accessions to NEW\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'splitting';\n",
    "\n",
    "## Reset SPLIT_ERR accessions to NEW\n",
    "## (repeated failures can be missing SRA data)\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'split_err';\n",
    "\n",
    "## Reset MERGE_ERR accessions to SPLIT_DONE\n",
    "# UPDATE acc SET state = 'split_done' WHERE state = 'merge_err';\n",
    "\n",
    "## Clear DONE Accessions (ONLY ON COMPLETION)\n",
    "# DELETE FROM acc WHERE state = 'merge_done';\n",
    "\n",
    "### BLOCK OPERATIONS\n",
    "\n",
    "##  Reset FAIL blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'fail';\n",
    "\n",
    "# Reset ALIGNING blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'aligning';\n",
    "\n",
    "# Clear Done\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "\n",
    "# RESET STATE\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "# DELETE FROM blocks WHERE state = 'fail';\n",
    "#\n",
    "#\n",
    "# DELETE FROM acc WHERE state = 'split_err';\n",
    "# DELETE FROM acc WHERE state = 'merging';\n",
    "# DELETE FROM acc WHERE state = 'merge_err';\n",
    "# DELETE FROM acc WHERE state = 'split_done';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuke Shutdown\n",
    "cd $TF\n",
    "\n",
    "aws ec2 describe-instances \\\n",
    "  --filter Name=tag:Name,Values=serratus-align-instance \\\n",
    "  > align_instances.json\n",
    "\n",
    "jq '.Reservations[].Instances[].InstanceId' -r align_instances.json \\\n",
    "  | pv -l \\\n",
    "  | xargs -n10 -P10 aws ec2 terminate-instances --instance-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./hutest_SraRunInfo.csv to s3://serratus-public/out/201025_pmito5/hutest_SraRunInfo.csv\n",
      "upload: ./viro1k_SraRunInfo.csv to s3://serratus-public/out/201025_pmito5/viro1k_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "\n",
    "aws s3 cp hutest_SraRunInfo.csv s3://serratus-public/out/201025_pmito5/\n",
    "aws s3 cp viro1k_SraRunInfo.csv s3://serratus-public/out/201025_pmito5/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
