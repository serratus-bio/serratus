{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run: rdrp1 Genome/Exome sequencing (mammal)\n",
    "\n",
    "```\n",
    "Lead     : ababaian\n",
    "Issue    : \n",
    "Version  : v0.4.0-dev : diamond-dev branch\n",
    "start    : 2021 01 21\n",
    "complete : 2021 01 xx\n",
    "files    : ~/serratus/notebook/210108_ab/\n",
    "s3_files : s3://serratus-public/notebook/210108_ab/\n",
    "output   : s3://serratus-public/out/210121_rWgs/\n",
    "```\n",
    "\n",
    "### Intro/Objectives\n",
    "\n",
    "> There are no separate things in the physical world, either. The physical world is wiggly. Clouds, mountains, trees, people, are all wiggly. And only when human beings get to working on things--they build buildings in straight lines, and try to make out that the world isn't really wiggly. But here we are, sitting in this room all built out of straight lines, but each one of us is as wiggly as all get-out.\n",
    "\n",
    "Searching for RNA viruses in DNA-sequencing data...\n",
    "\n",
    "### WGS (mammalian, non-mouse)\n",
    "\n",
    "- File: `wgs_SraRunInfo.csv`\n",
    "\n",
    "Search Term:\n",
    "```\n",
    "(\"Mammalia\"[Organism] NOT \"Mus musculus\"[orgn]) AND (\"type_exome\"[Filter] OR \"type_genome\"[Filter]) NOT \"METAGENOME\" AND \"platform illumina\"[Properties] AND cluster_public[prop]\n",
    "```\n",
    "SRA Accessed: `2021/01/21`\n",
    "\n",
    "Results: `330 239 / 393 278`\n",
    "\n",
    "[See: 201230_sraRunInfo_Update.ipynb](./201230_sraRunInfo_Update.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fire up EC2 Instance\n",
    "#sudo yum install -y docker\n",
    "#sudo yum install -y git\n",
    "#sudo service docker start\n",
    "\n",
    "## Download latest serratus repo\n",
    "#git clone -b diamond-dev https://github.com/ababaian/serratus.git; cd serratus/containers\n",
    "\n",
    "## If you want to upload containers to your repository, include this.\n",
    "#export DOCKERHUB_USER='serratusbio' # optional\n",
    "#sudo docker login # optional\n",
    "#\n",
    "## Build all containers and upload them docker hub repo (if available)\n",
    "#./build_containers.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 21 12:43:54 PST 2021\n",
      "2ddf24166fdded0bc89a96b2541bcbc7442f98f9\n"
     ]
    }
   ],
   "source": [
    "# Serratus commit version\n",
    "SERRATUS=\"/home/artem/serratus\"\n",
    "cd $SERRATUS\n",
    "\n",
    "# Create local run directory\n",
    "WORK=\"$SERRATUS/notebook/210111_ab\"\n",
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# S3 notebook path\n",
    "S3_WORK='s3://serratus-public/notebook/210111_ab'\n",
    "\n",
    "# date and version\n",
    "date\n",
    "git rev-parse HEAD # commit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link './wgs_SraRunInfo.csv': File exists\n",
      "47313cfe06b2fce2ada17a894a72a278  wgs_SraRunInfo.csv\n",
      "lrwxrwxrwx 1 artem artem 32 Jan 21 12:45 \u001b[0m\u001b[01;36mwgs_SraRunInfo.csv\u001b[0m -> ../201230_sra/wgs_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "\n",
    "# Copy SRA Run Info\n",
    "ln -s ../201230_sra/wgs_SraRunInfo.csv ./\n",
    "\n",
    "md5sum wgs*\n",
    "ls -alh wgs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail -n+2 wgs_SraRunInfo.csv | shuf - > wgs.tmp\n",
    "\n",
    "head -n 1 wgs_SraRunInfo.csv > wgs_1_SraRunInfo.csv\n",
    "head -n 175000 wgs.tmp      >> wgs_1_SraRunInfo.csv\n",
    "\n",
    "head -n 1 wgs_SraRunInfo.csv > wgs_2_SraRunInfo.csv\n",
    "tail -n+175000 wgs.tmp      >> wgs_2_SraRunInfo.csv\n",
    "\n",
    "rm wgs.tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aws s3 sync ./ $S3_WORK/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terraform Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UPDATE serratus/terraform/main/main.tf\n",
    "# main/main.tf LINE 187 = \"-b s3://serratus-public/out/yymmdd_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to ec2-3-208-57-35.compute-1.amazonaws.com closed by remote host.\n",
      "\u001b[1mdiff --git a/terraform/main/main.tf b/terraform/main/main.tf\u001b[m\n",
      "\u001b[1mindex de2d00d..e4fc917 100644\u001b[m\n",
      "\u001b[1m--- a/terraform/main/main.tf\u001b[m\n",
      "\u001b[1m+++ b/terraform/main/main.tf\u001b[m\n",
      "\u001b[36m@@ -12,14 +12,14 @@\u001b[m \u001b[mvariable \"aws_region\" {\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " variable \"dl_size\" {\u001b[m\n",
      "\u001b[31m-  type    = number\u001b[m\n",
      "\u001b[31m-  default = 0\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  type        = number\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  default     = 0\u001b[m\n",
      "   description = \"Default number of downloader nodes (ASG)\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " variable \"align_size\" {\u001b[m\n",
      "\u001b[31m-  type    = number\u001b[m\n",
      "\u001b[31m-  default = 0\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  type        = number\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  default     = 0\u001b[m\n",
      "   description = \"Default number of aligner nodes (ASG)\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      "\u001b[36m@@ -38,14 +38,22 @@\u001b[m \u001b[mvariable \"dockerhub_account\" {\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " variable \"scheduler_port\" {\u001b[m\n",
      "\u001b[31m-  type  = number\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  type    = number\u001b[m\n",
      "   default = 8000\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mvariable \"output_bucket\" {\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  type = string\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m}\u001b[m\n",
      "\u001b[32m+\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m//variable \"metrics_ip\" {\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m//  type = string\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m//}\u001b[m\n",
      "\u001b[32m+\u001b[m\n",
      " // PROVIDER/AWS ##############################\u001b[m\n",
      " provider \"aws\" {\u001b[m\n",
      "\u001b[31m-  version     = \"~> 2.49\"\u001b[m\n",
      "\u001b[31m-  region      = var.aws_region\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  version = \"~> 2.49\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  region  = var.aws_region\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " provider \"local\" {\u001b[m\n",
      "\u001b[36m@@ -81,68 +89,73 @@\u001b[m \u001b[mresource \"aws_security_group\" \"internal\" {\u001b[m\n",
      " \u001b[m\n",
      " // Working S3 storage for Serratus\u001b[m\n",
      " module \"work_bucket\" {\u001b[m\n",
      "\u001b[31m-  source   = \"../bucket\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../bucket\"\u001b[m\n",
      " \u001b[m\n",
      "   prefixes = [\"fq-blocks\", \"bam-blocks\", \"out\"]\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " // Cluster scheduler and task manager\u001b[m\n",
      " module \"scheduler\" {\u001b[m\n",
      "\u001b[31m-  source             = \"../scheduler\"\u001b[m\n",
      "\u001b[31m-  \u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../scheduler\"\u001b[m\n",
      "\u001b[32m+\u001b[m\n",
      "   security_group_ids = [aws_security_group.internal.id]\u001b[m\n",
      "   key_name           = var.key_name\u001b[m\n",
      "\u001b[31m-  instance_type      = \"c5.large\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  instance_type      = \"r5.4xlarge\"\u001b[m\n",
      "   dockerhub_account  = var.dockerhub_account\u001b[m\n",
      "   scheduler_port     = var.scheduler_port\u001b[m\n",
      "\u001b[32m+\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  //# https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  //pg_shared_buffers  = \"2GB\" # 1/4 of RAM\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  //pg_effective_cache = \"6GB\" # 3/4 of RAM\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " // Cluster monitor\u001b[m\n",
      " module \"monitoring\" {\u001b[m\n",
      "\u001b[31m-  source             = \"../monitoring\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../monitoring\"\u001b[m\n",
      " \u001b[m\n",
      "   security_group_ids = [aws_security_group.internal.id]\u001b[m\n",
      "   key_name           = var.key_name\u001b[m\n",
      "   scheduler_ip       = module.scheduler.private_ip\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  //metrics_ip         = var.metrics_ip\u001b[m\n",
      "   dockerhub_account  = var.dockerhub_account\u001b[m\n",
      "\u001b[31m-  instance_type      = \"r5.large\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  instance_type      = \"r5.2xlarge\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " // Serratus-dl\u001b[m\n",
      " module \"download\" {\u001b[m\n",
      "\u001b[31m-  source             = \"../worker\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../worker\"\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-  desired_size       = 0\u001b[m\n",
      "\u001b[31m-  max_size           = 200\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  desired_size = 0\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  max_size     = 5000\u001b[m\n",
      " \u001b[m\n",
      "   dev_cidrs          = var.dev_cidrs\u001b[m\n",
      "   security_group_ids = [aws_security_group.internal.id]\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-  instance_type      = \"r5.large\" // Mitigate the memory leak in fastq-dump\u001b[m\n",
      "\u001b[31m-  volume_size        = 250 // Mitigate the storage leak in fastq-dump\u001b[m\n",
      "\u001b[31m-  spot_price         = 0.10\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  instance_type = \"r5.xlarge\" // Mitigate the memory leak in fastq-dump\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  volume_size   = 100         // Mitigate the storage leak in fastq-dump\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  spot_price    = 0.12\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-  s3_bucket          = module.work_bucket.name\u001b[m\n",
      "\u001b[31m-  s3_prefix          = \"fq-blocks\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  s3_bucket = module.work_bucket.name\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  s3_prefix = \"fq-blocks\"\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-  image_name         = \"serratus-dl\"\u001b[m\n",
      "\u001b[31m-  dockerhub_account  = var.dockerhub_account\u001b[m\n",
      "\u001b[31m-  key_name           = var.key_name\u001b[m\n",
      "\u001b[31m-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\u001b[m\n",
      "\u001b[31m-  options            = \"-k ${module.work_bucket.name}\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  image_name        = \"serratus-dl\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  dockerhub_account = var.dockerhub_account\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  key_name          = var.key_name\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  options           = \"-k ${module.work_bucket.name}\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " // Serratus-align\u001b[m\n",
      " module \"align\" {\u001b[m\n",
      "\u001b[31m-  source             = \"../worker\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../worker\"\u001b[m\n",
      " \u001b[m\n",
      "   desired_size       = 0\u001b[m\n",
      "\u001b[31m-  max_size           = 500\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  max_size           = 10000\u001b[m\n",
      "   dev_cidrs          = var.dev_cidrs\u001b[m\n",
      "   security_group_ids = [aws_security_group.internal.id]\u001b[m\n",
      "\u001b[31m-  instance_type      = \"c5.large\" # c5.large\u001b[m\n",
      "\u001b[31m-  volume_size        = 10\u001b[m\n",
      "\u001b[31m-  spot_price         = 0.10\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  instance_type      = \"c5n.large\" # c5.large\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  volume_size        = 8\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  spot_price         = 0.08\u001b[m\n",
      "   s3_bucket          = module.work_bucket.name\u001b[m\n",
      "   s3_delete_prefix   = \"fq-blocks\"\u001b[m\n",
      "   s3_prefix          = \"bam-blocks\"\u001b[m\n",
      "\u001b[36m@@ -150,51 +163,46 @@\u001b[m \u001b[mmodule \"align\" {\u001b[m\n",
      "   image_name         = \"serratus-align\"\u001b[m\n",
      "   key_name           = var.key_name\u001b[m\n",
      "   scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\u001b[m\n",
      "\u001b[31m-  options            = \"-k ${module.work_bucket.name} -a bowtie2\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  options            = \"-k ${module.work_bucket.name} -a diamond\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " //Serratus-merge\u001b[m\n",
      " module \"merge\" {\u001b[m\n",
      "\u001b[31m-  source             = \"../worker\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  source = \"../worker\"\u001b[m\n",
      " \u001b[m\n",
      "   desired_size       = 0\u001b[m\n",
      "\u001b[31m-  max_size           = 50\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  max_size           = 1500\u001b[m\n",
      "   dev_cidrs          = var.dev_cidrs\u001b[m\n",
      "   security_group_ids = [aws_security_group.internal.id]\u001b[m\n",
      "   instance_type      = \"c5.large\"\u001b[m\n",
      "\u001b[31m-  volume_size        = 150 // prevent disk overflow via samtools cat\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  volume_size        = 100 // prevent disk overflow via samtools cat\u001b[m\n",
      "   spot_price         = 0.05\u001b[m\n",
      "   s3_bucket          = module.work_bucket.name\u001b[m\n",
      "\u001b[31m-  // TODO: Add delete permissions for *-blocks\u001b[m\n",
      "\u001b[31m-  // to merge as redundant delete of completed data\u001b[m\n",
      "\u001b[31m-  s3_delete_prefix   = \"bam-blocks\"\u001b[m\n",
      "\u001b[31m-  s3_prefix          = \"out\"\u001b[m\n",
      "\u001b[31m-  dockerhub_account  = var.dockerhub_account\u001b[m\n",
      "\u001b[31m-  image_name         = \"serratus-merge\"\u001b[m\n",
      "\u001b[31m-  key_name           = var.key_name\u001b[m\n",
      "\u001b[31m-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\u001b[m\n",
      "\u001b[31m-  // TODO: the credentials are not properly set-up to\u001b[m\n",
      "\u001b[31m-  //       upload to serratus-public, requires a *Object policy\u001b[m\n",
      "\u001b[31m-  //       on the bucket.\u001b[m\n",
      "\u001b[31m-  options            = \"-k ${module.work_bucket.name} -b ${var.output_bucket}\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  s3_delete_prefix  = \"bam-blocks\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  s3_prefix         = \"out\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  dockerhub_account = var.dockerhub_account\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  image_name        = \"serratus-merge\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  key_name          = var.key_name\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  options = \"-k ${module.work_bucket.name} -b s3://serratus-public/out/210121_rWgs\"\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " // RESOURCES ##############################\u001b[m\n",
      " // Controller scripts created locally\u001b[m\n",
      " \u001b[m\n",
      " resource \"local_file\" \"hosts\" {\u001b[m\n",
      "\u001b[31m-  filename = \"${path.module}/serratus-hosts\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  filename        = \"${path.module}/serratus-hosts\"\u001b[m\n",
      "   file_permission = 0666\u001b[m\n",
      "\u001b[31m-  content = <<-EOF\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  content         = <<-EOF\u001b[m\n",
      "     aws_monitor ${module.monitoring.public_dns}\u001b[m\n",
      "     aws_scheduler ${module.scheduler.public_dns}\u001b[m\n",
      "   EOF\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " resource \"local_file\" \"create_tunnel\" {\u001b[m\n",
      "\u001b[31m-  filename = \"${path.module}/create_tunnels.sh\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  filename        = \"${path.module}/create_tunnels.sh\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   file_permission = 0777\u001b[m\n",
      "\u001b[31m-  content = <<-EOF\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  content         = <<-EOF\u001b[m\n",
      "     #!/bin/bash\u001b[m\n",
      "     set -eu\u001b[m\n",
      "     ssh -Nf -L 3000:localhost:3000 -L 9090:localhost:9090 ec2-user@${module.monitoring.public_dns}\u001b[m\n",
      "\u001b[36m@@ -208,9 +216,9 @@\u001b[m \u001b[mresource \"local_file\" \"create_tunnel\" {\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      " resource \"local_file\" \"upload_sra\" {\u001b[m\n",
      "\u001b[31m-  filename = \"${path.module}/uploadSRA.sh\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  filename        = \"${path.module}/uploadSRA.sh\"\u001b[m\n",
      "   file_permission = 0777\u001b[m\n",
      "\u001b[31m-  content = <<-EOF\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m  content         = <<-EOF\u001b[m\n",
      "     #!/bin/bash\u001b[m\n",
      "     # =====================================\u001b[m\n",
      "     # Serratus - uploadSRA.sh\u001b[m\n",
      "\u001b[36m@@ -289,7 +297,6 @@\u001b[m \u001b[mresource \"local_file\" \"upload_sra\" {\u001b[m\n",
      "   EOF\u001b[m\n",
      " }\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-\u001b[m\n",
      " // OUTPUT ##############################\u001b[m\n",
      " output \"help\" {\u001b[m\n",
      "   value = <<-EOF\u001b[m\n",
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "\n",
      "The following providers do not have any version constraints in configuration,\n",
      "so the latest version was installed.\n",
      "\n",
      "To prevent automatic upgrades to new major versions that may contain breaking\n",
      "changes, it is recommended to add version = \"...\" constraints to the\n",
      "corresponding provider blocks in configuration, with the constraint strings\n",
      "suggested below.\n",
      "\n",
      "* provider.random: version = \"~> 2.2\"\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_availability_zones.all: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_region.current: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creation complete after 0s [id=none]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creation complete after 0s [id=db5deb3269742410535713cc6c7c3d53cbb21cfe]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor-20210122082928922000000002]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creation complete after 1s [id=serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 2s [id=instance-profile-serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-align-20210122082929843200000003]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-serratus-dl:CloudWatchLogsCreate-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-serratus-align:CloudWatchLogsCreate-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-dl-20210122082930722800000004]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creation complete after 1s [id=SerratusIamRole-monitor-20210122082930910900000005]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-monitor:CloudwatchGetMetrics]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creation complete after 1s [id=SerratusIamRole-scheduler:DescribeInstances-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-merge:CloudWatchLogsCreate-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creation complete after 5s [id=sg-08bcb0d0775145437]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-merge-20210122082931643800000006]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-align:TerminateEC2Instances-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-align:DescribeEC2Instances-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-align:AdjustAutoScaling-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creation complete after 0s [id=scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-dl:TerminateEC2Instances-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-dl:AdjustAutoScaling-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-dl:DescribeEC2Instances-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-merge:AdjustAutoScaling-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler-20210122082932790900000007]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creation complete after 0s [id=SerratusIamRole-serratus-merge:DescribeEC2Instances-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-merge:TerminateEC2Instances-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 2s [id=instance-profile-serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creation complete after 8s [id=tf-serratus-work-20210122082927182800000001]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20210122082927182800000001:prefix-fq-blocks]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creation complete after 1s [id=tf-serratus-work-20210122082927182800000001:full]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20210122082927182800000001:prefix-bam-blocks]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3DeleteData-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3DeleteData-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3WriteData-serratus-align]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-dl:S3WriteData-serratus-dl]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creation complete after 1s [id=tf-serratus-work-20210122082927182800000001:prefix-out]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3WriteData-serratus-merge]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 12s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 12s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-scheduler/serratus-scheduler]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creation complete after 17s [id=i-03bff2dfc6440a21b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-0f1dafdce020a1127]\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creation complete after 1s [id=monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-monitor/serratus-monitor]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creation complete after 3s [id=eipalloc-07d966d99a6e62d90]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creation complete after 3s [id=eipalloc-093a4e6971c4f9174]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creation complete after 0s [id=9a387b991b591cda41a18209bfe30128feebfd5b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creation complete after 0s [id=ef00388df4913a9e5b75d7b3adae3ed3e847d6a9]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-merge-2021012208295998350000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-align-2021012208300003820000000b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creation complete after 3s [id=serratus-dl-2021012208300003890000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-merge-2021012208295998350000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-dl-2021012208300003890000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creation complete after 2s [id=serratus-align-2021012208300003820000000b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creation complete after 2s [id=serratus-merge-2021012208295998350000000a]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-dl-2021012208300003890000000c]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-align-2021012208300003820000000b]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 71 added, 0 changed, 0 destroyed.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "align_asg_name = serratus-align-2021012208300003820000000b\n",
      "dl_asg_name = serratus-dl-2021012208300003890000000c\n",
      "help = Run ./create_tunnels.sh to create SSH tunnels for all services.\n",
      "\n",
      "merge_asg_name = serratus-merge-2021012208295998350000000a\n",
      "monitor_dns = ec2-54-92-148-27.compute-1.amazonaws.com\n",
      "scheduler_dns = ec2-34-231-214-6.compute-1.amazonaws.com\n",
      "scheduler_pg_password = FnLQnrYMb3V5UK53\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For rapid batching; copy out serratus folder\n",
    "# PROTEIN / DNA MUST BE SET IN CONFIG FILE\n",
    "# main/main.tf LINE 166\n",
    "#   options            = \"-k ${module.work_bucket.name} -a bowtie2\"\n",
    "#   options            = \"-k ${module.work_bucket.name} -a diamond\"\n",
    "# Set output location\n",
    "# main/main.tf LINE 187 = \"-b s3://serratus-public/out/yymmdd_id\"\n",
    "\n",
    "TF=$SERRATUS/terraform/main\n",
    "cd $TF\n",
    "git diff main.tf\n",
    "terraform init\n",
    "\n",
    "# Launch Terraform Cluster\n",
    "# Initialize the serratus cluster with minimal nodes\n",
    "terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serratus Config backup \n",
    "```\n",
    "{\n",
    "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\n",
    "  \"ALIGN_MAX_INCREASE\": 40,\n",
    "  \"ALIGN_SCALING_CONSTANT\": 0.08,\n",
    "  \"ALIGN_SCALING_ENABLE\": true,\n",
    "  \"ALIGN_SCALING_MAX\": 3200,\n",
    "  \"CLEAR_INTERVAL\": 999999,\n",
    "  \"DL_ARGS\": \"\",\n",
    "  \"DL_MAX_INCREASE\": 20,\n",
    "  \"DL_SCALING_CONSTANT\": 0.1,\n",
    "  \"DL_SCALING_ENABLE\": true,\n",
    "  \"DL_SCALING_MAX\": 1350,\n",
    "  \"GENOME\": \"rdrp1\",\n",
    "  \"MERGE_ARGS\": \"protein\",\n",
    "  \"MERGE_MAX_INCREASE\": 25,\n",
    "  \"MERGE_SCALING_CONSTANT\": 0.1,\n",
    "  \"MERGE_SCALING_ENABLE\": true,\n",
    "  \"MERGE_SCALING_MAX\": 25,\n",
    "  \"SCALING_INTERVAL\": 120,\n",
    "  \"VIRTUAL_SCALING_INTERVAL\": 35\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'ec2-54-92-148-27.compute-1.amazonaws.com,54.92.148.27' (ECDSA) to the list of known hosts.\n",
      "Warning: Permanently added 'ec2-34-231-214-6.compute-1.amazonaws.com,34.231.214.6' (ECDSA) to the list of known hosts.\n",
      "Tunnels created:\n",
      "    localhost:3000 = grafana\n",
      "    localhost:9090 = prometheus\n",
      "    localhost:5432 = postgres\n",
      "    localhost:8000 = scheduler\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "\n",
    "# Open SSH tunnels to the monitor\n",
    "./create_tunnels.sh\n",
    "\n",
    "# If you get an error on port\n",
    "# run:\n",
    "# ps aux | grep ssh\n",
    "# sudo kill <PID of SSH>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175001 /home/artem/serratus/notebook/210111_ab/wgs_1_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "# BATCH 1\n",
    "cd $WORK\n",
    "BATCH1='wgs_1_SraRunInfo.csv'\n",
    "wc -l $WORK/$BATCH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \n",
      "  File: /home/artem/serratus/notebook/210111_ab/wgs_1_SraRunInfo.csv\n",
      "  date: Thu Jan 21 13:23:47 PST 2021\n",
      "  wc  : 175001 /home/artem/serratus/notebook/210111_ab/wgs_1_SraRunInfo.csv\n",
      "  md5 : f20598c51b01785aa28a7744c0e0d129  /home/artem/serratus/notebook/210111_ab/wgs_1_SraRunInfo.csv\n",
      "\n",
      "\n",
      "--------------------------\n",
      "tmp.chunk00\n",
      "10001 tmp.chunk00_sraRunInfo.csv\n",
      "63e4820c945370e11d21609bd7784ed8  tmp.chunk00_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":10000}\n",
      "--------------------------\n",
      "tmp.chunk01\n",
      "10001 tmp.chunk01_sraRunInfo.csv\n",
      "a7f8aba288d55613464834819bb62500  tmp.chunk01_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":20000}\n",
      "--------------------------\n",
      "tmp.chunk02\n",
      "10001 tmp.chunk02_sraRunInfo.csv\n",
      "38f57c1b6109d0831e419f1f07b007f1  tmp.chunk02_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":30000}\n",
      "--------------------------\n",
      "tmp.chunk03\n",
      "10001 tmp.chunk03_sraRunInfo.csv\n",
      "39648e2f6f345c2b519001cc6e34a0e5  tmp.chunk03_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":40000}\n",
      "--------------------------\n",
      "tmp.chunk04\n",
      "10001 tmp.chunk04_sraRunInfo.csv\n",
      "beb8805acf9bfd4c3e340f14df22c49e  tmp.chunk04_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":50000}\n",
      "--------------------------\n",
      "tmp.chunk05\n",
      "10001 tmp.chunk05_sraRunInfo.csv\n",
      "092228f442cb76fd433ca6467d67fbe5  tmp.chunk05_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":60000}\n",
      "--------------------------\n",
      "tmp.chunk06\n",
      "10001 tmp.chunk06_sraRunInfo.csv\n",
      "d6f5c5e3aed6a4bd9d56938b865fa4b4  tmp.chunk06_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":70000}\n",
      "--------------------------\n",
      "tmp.chunk07\n",
      "10001 tmp.chunk07_sraRunInfo.csv\n",
      "0305514b67e13a058c03fe86cbd57055  tmp.chunk07_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":80000}\n",
      "--------------------------\n",
      "tmp.chunk08\n",
      "10001 tmp.chunk08_sraRunInfo.csv\n",
      "2e6b90f635cc4bd62490cb458d6deb45  tmp.chunk08_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":90000}\n",
      "--------------------------\n",
      "tmp.chunk09\n",
      "10001 tmp.chunk09_sraRunInfo.csv\n",
      "92a446af8edbdca3286d0ee1d606a6b7  tmp.chunk09_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":100000}\n",
      "--------------------------\n",
      "tmp.chunk10\n",
      "10001 tmp.chunk10_sraRunInfo.csv\n",
      "ff623b78084c058aa4ba075d0f9e9f0a  tmp.chunk10_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":110000}\n",
      "--------------------------\n",
      "tmp.chunk11\n",
      "10001 tmp.chunk11_sraRunInfo.csv\n",
      "b052a489098cc938e2fe67945453b255  tmp.chunk11_sraRunInfo.csv\n",
      "{\"inserted_rows\":9999,\"total_rows\":119999}\n",
      "--------------------------\n",
      "tmp.chunk12\n",
      "10001 tmp.chunk12_sraRunInfo.csv\n",
      "cb1ade90f6953d4b00a62510980f9f03  tmp.chunk12_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":129999}\n",
      "--------------------------\n",
      "tmp.chunk13\n",
      "10001 tmp.chunk13_sraRunInfo.csv\n",
      "78113e129dc10024147664288d6c5b8b  tmp.chunk13_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":139999}\n",
      "--------------------------\n",
      "tmp.chunk14\n",
      "10001 tmp.chunk14_sraRunInfo.csv\n",
      "17ff0b84f5ffb6c593307b884676c99a  tmp.chunk14_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":149999}\n",
      "--------------------------\n",
      "tmp.chunk15\n",
      "10001 tmp.chunk15_sraRunInfo.csv\n",
      "52c207e7bd9b0fa06754d54d0e6ef72a  tmp.chunk15_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":159999}\n",
      "--------------------------\n",
      "tmp.chunk16\n",
      "10001 tmp.chunk16_sraRunInfo.csv\n",
      "4b963685dac0c3a630593af79e50899f  tmp.chunk16_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":169999}\n",
      "--------------------------\n",
      "tmp.chunk17\n",
      "5001 tmp.chunk17_sraRunInfo.csv\n",
      "c61311a3804e0885899cea832c81c764  tmp.chunk17_sraRunInfo.csv\n",
      "{\"inserted_rows\":5000,\"total_rows\":174999}\n",
      "\n",
      "\n",
      " uploadSRA complete.\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $WORK/$BATCH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218279 /home/artem/serratus/notebook/210111_ab/wgs_2_SraRunInfo.csv\n"
     ]
    }
   ],
   "source": [
    "# BATCH 2\n",
    "cd $WORK\n",
    "BATCH2='wgs_2_SraRunInfo.csv'\n",
    "wc -l $WORK/$BATCH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \n",
      "  File: /home/artem/serratus/notebook/210111_ab/wgs_2_SraRunInfo.csv\n",
      "  date: Fri Jan 22 00:40:12 PST 2021\n",
      "  wc  : 218279 /home/artem/serratus/notebook/210111_ab/wgs_2_SraRunInfo.csv\n",
      "  md5 : a271a34380cea0f560935f091a8dc2b6  /home/artem/serratus/notebook/210111_ab/wgs_2_SraRunInfo.csv\n",
      "\n",
      "\n",
      "--------------------------\n",
      "tmp.chunk00\n",
      "10001 tmp.chunk00_sraRunInfo.csv\n",
      "90e8bfb2ae1137a7ba83848d61c44014  tmp.chunk00_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":10000}\n",
      "--------------------------\n",
      "tmp.chunk01\n",
      "10001 tmp.chunk01_sraRunInfo.csv\n",
      "cce05d1964c42da404cbfc9a19b9f737  tmp.chunk01_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":20000}\n",
      "--------------------------\n",
      "tmp.chunk02\n",
      "10001 tmp.chunk02_sraRunInfo.csv\n",
      "d52abcb8033bbbfe53f2158e528965db  tmp.chunk02_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":30000}\n",
      "--------------------------\n",
      "tmp.chunk03\n",
      "10001 tmp.chunk03_sraRunInfo.csv\n",
      "ffde292a0274d8858fd09a3c4a3b63b1  tmp.chunk03_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":40000}\n",
      "--------------------------\n",
      "tmp.chunk04\n",
      "10001 tmp.chunk04_sraRunInfo.csv\n",
      "b15df8b3b37039bcbd7c17853ce9de89  tmp.chunk04_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":50000}\n",
      "--------------------------\n",
      "tmp.chunk05\n",
      "10001 tmp.chunk05_sraRunInfo.csv\n",
      "9d341c6fb6309d7e140fe90367b864d7  tmp.chunk05_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":60000}\n",
      "--------------------------\n",
      "tmp.chunk06\n",
      "10001 tmp.chunk06_sraRunInfo.csv\n",
      "07a6bb9f0d0e1cd294940a927804dc72  tmp.chunk06_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":70000}\n",
      "--------------------------\n",
      "tmp.chunk07\n",
      "10001 tmp.chunk07_sraRunInfo.csv\n",
      "6a3dd399f8f431ef336410ba33775681  tmp.chunk07_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":80000}\n",
      "--------------------------\n",
      "tmp.chunk08\n",
      "10001 tmp.chunk08_sraRunInfo.csv\n",
      "aacdf81f01ed12c29e9a1ab82925c86a  tmp.chunk08_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":90000}\n",
      "--------------------------\n",
      "tmp.chunk09\n",
      "10001 tmp.chunk09_sraRunInfo.csv\n",
      "eb0cd185e8af6520da2d018b31259e16  tmp.chunk09_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":100000}\n",
      "--------------------------\n",
      "tmp.chunk10\n",
      "10001 tmp.chunk10_sraRunInfo.csv\n",
      "19bdedb855145bcdcd6ccc7c9b96db5a  tmp.chunk10_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":110000}\n",
      "--------------------------\n",
      "tmp.chunk11\n",
      "10001 tmp.chunk11_sraRunInfo.csv\n",
      "ba69f92d52824bd0a53ca13c982d852a  tmp.chunk11_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":120000}\n",
      "--------------------------\n",
      "tmp.chunk12\n",
      "10001 tmp.chunk12_sraRunInfo.csv\n",
      "5d9e43127a8d989145bd5608e5e6ef05  tmp.chunk12_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":130000}\n",
      "--------------------------\n",
      "tmp.chunk13\n",
      "10001 tmp.chunk13_sraRunInfo.csv\n",
      "0b0bf26271804676e90cdaa8855907b0  tmp.chunk13_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":140000}\n",
      "--------------------------\n",
      "tmp.chunk14\n",
      "10001 tmp.chunk14_sraRunInfo.csv\n",
      "12a0f0431b1fd1501fdc87ea6933c464  tmp.chunk14_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":150000}\n",
      "--------------------------\n",
      "tmp.chunk15\n",
      "10001 tmp.chunk15_sraRunInfo.csv\n",
      "f2597905023a5ea1db65d046ff0996e0  tmp.chunk15_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":160000}\n",
      "--------------------------\n",
      "tmp.chunk16\n",
      "10001 tmp.chunk16_sraRunInfo.csv\n",
      "5840be02231dd9c9c357149b39ac54b7  tmp.chunk16_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":170000}\n",
      "--------------------------\n",
      "tmp.chunk17\n",
      "10001 tmp.chunk17_sraRunInfo.csv\n",
      "6aff501082f34835a1c41794f34cc224  tmp.chunk17_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":180000}\n",
      "--------------------------\n",
      "tmp.chunk18\n",
      "10001 tmp.chunk18_sraRunInfo.csv\n",
      "c34f98d26d3f07af6bf20cee1c7f6f02  tmp.chunk18_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":190000}\n",
      "--------------------------\n",
      "tmp.chunk19\n",
      "10001 tmp.chunk19_sraRunInfo.csv\n",
      "c4d57c91370694ef900ea2c5b170611c  tmp.chunk19_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":200000}\n",
      "--------------------------\n",
      "tmp.chunk20\n",
      "10001 tmp.chunk20_sraRunInfo.csv\n",
      "f11051d4bc96ccc37f9c1aea2015e3a0  tmp.chunk20_sraRunInfo.csv\n",
      "{\"inserted_rows\":10000,\"total_rows\":210000}\n",
      "--------------------------\n",
      "tmp.chunk21\n",
      "8279 tmp.chunk21_sraRunInfo.csv\n",
      "c98e723a2766b3e8b15744a73aca65b9  tmp.chunk21_sraRunInfo.csv\n",
      "{\"inserted_rows\":8278,\"total_rows\":218278}\n",
      "\n",
      "\n",
      " uploadSRA complete.\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $WORK/$BATCH2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Serratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_loop: send disconnect: Broken pipe\n",
      "  Cluster Config File: \n",
      "{\n",
      "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\n",
      "  \"ALIGN_MAX_INCREASE\": 35,\n",
      "  \"ALIGN_SCALING_CONSTANT\": 0.1,\n",
      "  \"ALIGN_SCALING_ENABLE\": true,\n",
      "  \"ALIGN_SCALING_MAX\": 2250,\n",
      "  \"CLEAR_INTERVAL\": 300,\n",
      "  \"DL_ARGS\": \"\",\n",
      "  \"DL_MAX_INCREASE\": 20,\n",
      "  \"DL_SCALING_CONSTANT\": 0.1,\n",
      "  \"DL_SCALING_ENABLE\": true,\n",
      "  \"DL_SCALING_MAX\": 1200,\n",
      "  \"GENOME\": \"rdrp1\",\n",
      "  \"MERGE_ARGS\": \"protein\",\n",
      "  \"MERGE_MAX_INCREASE\": 35,\n",
      "  \"MERGE_SCALING_CONSTANT\": 0.1,\n",
      "  \"MERGE_SCALING_ENABLE\": true,\n",
      "  \"MERGE_SCALING_MAX\": 35,\n",
      "  \"SCALING_INTERVAL\": 120,\n",
      "  \"VIRTUAL_SCALING_INTERVAL\": 35\n",
      "}\n",
      "\n",
      "{\"ALIGN_ARGS\":\"--very-sensitive-local\",\"ALIGN_MAX_INCREASE\":35,\"ALIGN_SCALING_CONSTANT\":0.1,\"ALIGN_SCALING_ENABLE\":true,\"ALIGN_SCALING_MAX\":2250,\"CLEAR_INTERVAL\":300,\"DL_ARGS\":\"\",\"DL_MAX_INCREASE\":20,\"DL_SCALING_CONSTANT\":0.1,\"DL_SCALING_ENABLE\":true,\"DL_SCALING_MAX\":1200,\"GENOME\":\"rdrp1\",\"MERGE_ARGS\":\"protein\",\"MERGE_MAX_INCREASE\":35,\"MERGE_SCALING_CONSTANT\":0.1,\"MERGE_SCALING_ENABLE\":true,\"MERGE_SCALING_MAX\":35,\"SCALING_INTERVAL\":120,\"VIRTUAL_SCALING_INTERVAL\":35}\n"
     ]
    }
   ],
   "source": [
    "# Set Cluster Parameters =============================\n",
    "## get Config File (if it doesn't exist)\n",
    "# curl localhost:8000/config | jq > serratus-config.json\n",
    "\n",
    "cd $TF\n",
    "# Make local changes to config file\n",
    "echo \"  Cluster Config File: \"\n",
    "cat serratus-config.json\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "# Re-upload config file\n",
    "curl -sT serratus-config.json localhost:8000/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop postgres if it's running \n",
    "# systemctl stop postgresql\n",
    "\n",
    "## Connect to postgres\n",
    "# psql -h localhost postgres postgres\n",
    "\n",
    "#  psql -h localhost postgres postgres -c \"DELETE FROM blocks WHERE state = 'done';\"\n",
    "\n",
    "### ACCESSION OPERATIONS\n",
    "## Reset SPLITTING accessions to NEW\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'splitting';\n",
    "\n",
    "## Reset SPLIT_ERR accessions to NEW\n",
    "## (repeated failures can be missing SRA data)\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'split_err';\n",
    "\n",
    "## Reset MERGE_ERR accessions to SPLIT_DONE\n",
    "# UPDATE acc SET state = 'split_done' WHERE state = 'merge_err';\n",
    "\n",
    "## Clear DONE Accessions (ONLY ON COMPLETION)\n",
    "# DELETE FROM acc WHERE state = 'merge_done';\n",
    "\n",
    "### BLOCK OPERATIONS\n",
    "\n",
    "##  Reset FAIL blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'fail';\n",
    "\n",
    "# Reset ALIGNING blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'aligning';\n",
    "\n",
    "# Clear Done\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "\n",
    "# RESET STATE\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "# DELETE FROM blocks WHERE state = 'fail';\n",
    "#\n",
    "#\n",
    "# DELETE FROM acc WHERE state = 'split_err';\n",
    "# DELETE FROM acc WHERE state = 'merging';\n",
    "# DELETE FROM acc WHERE state = 'merge_err';\n",
    "# DELETE FROM acc WHERE state = 'split_done';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Shutdown\n",
    "cd $TF\n",
    "terraform destroy\n",
    "\n",
    "## Nuke Shutdown\n",
    "#cd $TF\n",
    "#\n",
    "#aws ec2 describe-instances \\\n",
    "#  --filter Name=tag:Name,Values=serratus-align-instance \\\n",
    "#  > align_instances.json\n",
    "#\n",
    "#jq '.Reservations[].Instances[].InstanceId' -r align_instances.json \\\n",
    "#  | pv -l \\\n",
    "#  | xargs -n10 -P10 aws ec2 terminate-instances --instance-ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "psummary: `https://serratus-public.s3.amazonaws.com/out/210108_r1p/psummary/<SRA>.psummary`\n",
    "\n",
    "SRA site: `https://www.ncbi.nlm.nih.gov/sra/?term=<SRA>`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
